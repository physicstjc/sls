<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sound Waveform Visualizer</title>
    <style>
        canvas {
            width: 100%;
            height: 400px;
            border: 1px solid black;
        }
        .controls {
            margin-top: 10px;
        }
        .time-axis {
            margin-top: 10px;
            font-family: monospace;
        }
    </style>
</head>
<body>
    <h1>Sound Waveform Visualizer</h1>
    <button id="startButton">Start Visualization</button>
    <button id="freezeButton">Freeze Waveform</button>
    <canvas id="waveformCanvas"></canvas>
    <div class="controls">
        <label for="scaleX">Scale X-axis:</label>
        <input type="range" id="scaleX" min="0.01" max="10" value="0.1">
        <label for="scaleY">Scale Y-axis:</label>
        <input type="range" id="scaleY" min="0.01" max="10" value="0.1">
    </div>
    <div id="timeAxis" class="time-axis"></div>

    <script>
        const canvas = document.getElementById('waveformCanvas');
        const ctx = canvas.getContext('2d');
        const scaleXInput = document.getElementById('scaleX');
        const scaleYInput = document.getElementById('scaleY');
        const startButton = document.getElementById('startButton');
        const freezeButton = document.getElementById('freezeButton');
        const timeAxis = document.getElementById('timeAxis');

        let audioContext, analyser, dataArray, bufferLength;
        let scaleX = 1;
        let scaleY = 1;
        let isFrozen = false;

        async function setupAudio() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log("Sampling Rate:", audioContext.sampleRate, "Hz");

                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const source = audioContext.createMediaStreamSource(stream);

                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                bufferLength = analyser.frequencyBinCount;
                dataArray = new Uint8Array(bufferLength);

                source.connect(analyser);
                console.log("Audio setup complete");
                drawWaveform();
            } catch (error) {
                console.error("Error setting up audio", error);
            }
        }

        function drawWaveform() {
            if (isFrozen) return;
            requestAnimationFrame(drawWaveform);

            analyser.getByteTimeDomainData(dataArray);

            ctx.clearRect(0, 0, canvas.width, canvas.height);

            // Draw the waveform
            ctx.lineWidth = 1;  // Thinner line
            ctx.strokeStyle = 'black';
            ctx.beginPath();

            const sliceWidth = (canvas.width * scaleX) / bufferLength;
            let x = 0;

            for (let i = 0; i < bufferLength; i++) {
                const v = dataArray[i] / 128.0;
                const y = (v * canvas.height / 2) * scaleY;

                if (i === 0) {
                    ctx.moveTo(x, y);
                } else {
                    ctx.lineTo(x, y);
                }

                x += sliceWidth;
            }

            ctx.lineTo(canvas.width, canvas.height / 2);
            ctx.stroke();

            // Update time axis display
            updateTimeAxis(sliceWidth);
        }

        function updateTimeAxis(sliceWidth) {
            const timePerSample = 1 / audioContext.sampleRate;
            const totalTime = sliceWidth * bufferLength * scaleX * timePerSample;
            const startTime = 0;
            const endTime = totalTime;

            timeAxis.textContent = `Time Axis: Start = ${startTime.toExponential(3)} s, End = ${endTime.toExponential(3)} s`;
        }

        scaleXInput.addEventListener('input', (e) => {
            scaleX = e.target.value;
        });

        scaleYInput.addEventListener('input', (e) => {
            scaleY = e.target.value;
        });

        startButton.addEventListener('click', () => {
            if (audioContext && audioContext.state === 'suspended') {
                audioContext.resume();
            } else {
                setupAudio();
            }
            isFrozen = false;
        });

        freezeButton.addEventListener('click', () => {
            isFrozen = true;
        });

        setupAudio();
    </script>
</body>
</html>
